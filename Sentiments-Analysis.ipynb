{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis remains one of the key problems that has seen extensive application of natural language processing. This time around, given the tweets from customers about various tech firms who manufacture and sell mobiles, computers, laptops, etc, the task is to identify if the tweets have a negative sentiment towards such companies or products.\n",
    "\n",
    " \n",
    "\n",
    "Evaluation Metric\n",
    "The metric used for evaluating the performance of classification model would be weighted F1-Score.\n",
    "\n",
    "Data\n",
    "train.csv - For training the models, we provide a labelled dataset of 7920 tweets. The dataset is provided in the form of a csv file with each line storing a tweet id, its label and the tweet.\n",
    "\n",
    "test.csv - The test data file contains only tweet ids and the tweet text with each tweet in a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  7921  I hate the new #iphone upgrade. Won't let me d...\n",
       "1  7922  currently shitting my fucking pants. #apple #i...\n",
       "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3  7924  My ipod is officially dead. I lost all my pict...\n",
       "4  7925  Been fighting iTunes all night! I only want th..."
      ]
     },
     "execution_count": 1185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1    0.0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2    0.0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3    0.0  We love this! Would you go? #talk #makememorie...\n",
       "3   4    0.0  I'm wired I know I'm George I was made that wa...\n",
       "4   5    1.0  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train,test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7920, 3), (1953, 2), (9873, 3))"
      ]
     },
     "execution_count": 1187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "label    float64\n",
       "tweet     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "label    1953\n",
       "tweet       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()    # label is expected one as test dataset does not have label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5894\n",
       "1.0    2026\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ed35037e88>"
      ]
     },
     "execution_count": 1191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Raw tweets\n",
    "def clean_text(text):\n",
    "    \n",
    "    #remove emails\n",
    "    text = ' '.join([i for i in text.split() if '@' not in i])\n",
    "    \n",
    "    #remove web address\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    \n",
    "    #Filter to allow only alphabets\n",
    "    text = re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "    \n",
    "    #Remove Unicode characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    #Convert to lowercase to maintain consistency\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove double spaces \n",
    "    text = re.sub('\\s+', ' ',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df[\"clean_tweet\"] = df['tweet'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "      <td>fingerprint pregnancy test android apps beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "      <td>finally a transparant silicon case thanks to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "      <td>we love this would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "      <td>i'm wired i know i'm george i was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "      <td>what amazing service apple won't even talk to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  #fingerprint #Pregnancy Test https://goo.gl/h1...   \n",
       "1   2    0.0  Finally a transparant silicon case ^^ Thanks t...   \n",
       "2   3    0.0  We love this! Would you go? #talk #makememorie...   \n",
       "3   4    0.0  I'm wired I know I'm George I was made that wa...   \n",
       "4   5    1.0  What amazing service! Apple won't even talk to...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0   fingerprint pregnancy test android apps beaut...  \n",
       "1  finally a transparant silicon case thanks to m...  \n",
       "2  we love this would you go talk makememories un...  \n",
       "3  i'm wired i know i'm george i was made that wa...  \n",
       "4  what amazing service apple won't even talk to ...  "
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining stop words\n",
    "STOP_WORDS = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'also', 'am', 'an', 'and',\n",
    "              'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below',\n",
    "              'between', 'both', 'but', 'by', 'can', \"can't\", 'cannot', 'com', 'could', \"couldn't\", 'did',\n",
    "              \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'else', 'ever',\n",
    "              'few', 'for', 'from', 'further', 'get', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having',\n",
    "              'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how',\n",
    "              \"how's\", 'however', 'http', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it',\n",
    "              \"it's\", 'its', 'itself', 'just', 'k', \"let's\", 'like', 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    "              'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'otherwise', 'ought', 'our', 'ours',\n",
    "              'ourselves', 'out', 'over', 'own', 'r', 'same', 'shall', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\",\n",
    "              'should', \"shouldn't\", 'since', 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs',\n",
    "              'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\n",
    "              \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\",\n",
    "              'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
    "              \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\",\n",
    "              'www', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "df['cleaned_tweets'] = df['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.porter import PorterStemmer\n",
    "#ps = PorterStemmer()\n",
    "#df['cleaned_tweets'] = df['clean_tweet'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split() if word not in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "#df['cleaned_tweets'] = df['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature length of tweet\n",
    "df['word_count'] = df['cleaned_tweets'].str.split().apply(lambda x :len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop not needed features\n",
    "df_1 = df.copy()\n",
    "df.drop(['tweet','clean_tweet'],axis=1,inplace=True)\n",
    "#df.drop(['tweet','clean_tweet','word_count'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fingerprint pregnancy test android apps beauti...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>finally transparant silicon case thanks uncle ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>love go talk makememories unplug relax iphone ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wired know george made way iphone cute daventr...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amazing service apple even talk question unles...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                     cleaned_tweets  word_count\n",
       "0   1    0.0  fingerprint pregnancy test android apps beauti...          12\n",
       "1   2    0.0  finally transparant silicon case thanks uncle ...          11\n",
       "2   3    0.0  love go talk makememories unplug relax iphone ...          10\n",
       "3   4    0.0  wired know george made way iphone cute daventr...           9\n",
       "4   5    1.0  amazing service apple even talk question unles...          10"
      ]
     },
     "execution_count": 1200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:7920]\n",
    "test = df[7920:]\n",
    "df_t = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7920, 4), (1953, 4))"
      ]
     },
     "execution_count": 1202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('label',axis=1)\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7920, 3), (7920,))"
      ]
     },
     "execution_count": 1204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('label',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X['cleaned_tweets'].astype('category')\n",
    "#X = X['word_count'].astype('category')\n",
    "test = test['cleaned_tweets'].astype('category')\n",
    "#test = test['word_count'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test Split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To perform further analysis we need to transform our data into a format that can be processed by our machine learning models.\n",
    "\n",
    "- CountVectorizer does text preprocessing, tokenizing and filtering of stopwords and it builds a dictionary of features and transform documents to feature vectors.\n",
    "- TfidfTransformer transforms the above vector by dividing the number of occurrences of each word in a document by the total number of words in the document. These new features are called tf or Term Frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features = 2500)\n",
    "vect.fit(X)\n",
    "X_train_vec = vect.transform(X)\n",
    "X_test_vec = vect.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100,max_depth=5)\n",
    "model.fit(X_train_vec,y)\n",
    "rf = model.predict(X_test_vec)\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":rf\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(max_iter=5, tol=None)\n",
    "clf.fit(X_train_vec, y)\n",
    "y_pred_SGD = clf.predict(X_test_vec)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":y_pred_SGD\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission_SGD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier = xgboost.XGBClassifier(n_estimators=210)\n",
    "classifier.fit(X_train_vec, y)\n",
    "# Predicting the Test set results\n",
    "y_pred_XGB = classifier.predict(X_test_vec)\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":y_pred_XGB\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission_XGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vec, y)\n",
    "y_pred_log_reg = clf.predict(X_test_vec)\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":y_pred_log_reg\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission_LRG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "clf.fit(X_train_vec, y)\n",
    "y_pred_knn = clf.predict(X_test_vec)\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":y_pred_knn\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission_knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(max_iter=6, tol=None)\n",
    "clf.fit(X_train_vec, y)\n",
    "y_pred_perceptron = clf.predict(X_test_vec)\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":y_pred_perceptron\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission_per.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for lightgbm features needed is in float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec=X_train_vec.astype('float64')\n",
    "X_test_vec=X_test_vec.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7920x2500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 67107 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data=lgb.Dataset(X_train_vec,label=y)\n",
    "#define parameters\n",
    "params = {'n_estimators':213,'objective':'binary','learning_rate':0.2,'max_depth': 10,'num_leaves':'100','min_data_in_leaf':9,'max_bin':100,'boosting_type':'gbdt',}\n",
    "model= lgb.train(params, train_data, 100) \n",
    "y_pred_LGB=model.predict(X_test_vec)\n",
    "#rounding the values\n",
    "y_pred_LGB=y_pred_LGB.round(0)\n",
    "#converting from float to integer\n",
    "y_pred_LGB=y_pred_LGB.astype(int)\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": df_t[\"id\"],\n",
    "        \"label\":y_pred_LGB\n",
    "    })\n",
    "\n",
    "submission.to_csv('sentiments_submission_LGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
